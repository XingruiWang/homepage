<!DOCTYPE html>
<html lang="en">
<head>
  <meta charset="utf-8">
  <meta name="description" content="KeyVID: Keyframe-Aware Video Diffusion for Audio-Synchronized Visual Animation">
  <meta name="keywords" content="audio to video, video generation, multimodal, AI, diffusion model">
  <meta name="viewport" content="width=device-width, initial-scale=1">
  <title>KeyVID: Keyframe-Aware Video Diffusion</title>
  
  <!-- Fonts -->
  <link href="https://fonts.googleapis.com/css2?family=Inter:wght@300;400;500;600;700&family=JetBrains+Mono:wght@400;500&display=swap" rel="stylesheet">
  <link rel="stylesheet" href="https://cdnjs.cloudflare.com/ajax/libs/font-awesome/6.0.0/css/all.min.css">
  
  <style>
    * {
      margin: 0;
      padding: 0;
      box-sizing: border-box;
    }

    body {
      font-family: 'Inter', sans-serif;
      line-height: 1.65;
      color: #2d3748;
      background: #ffffff;
      font-size: 16px;
    }

    .container {
      max-width: 1000px;
      margin: 0 auto;
      padding: 0 24px;
    }

    /* Typography */
    h1, h2, h3, h4 {
      font-weight: 600;
      color: #1a202c;
      line-height: 1.3;
    }

    h1 { font-size: 2.5rem; }
    h2 { font-size: 2rem; }
    h3 { font-size: 1.5rem; }
    h4 { font-size: 1.25rem; }

    /* Header */
    .header {
      background: rgba(255, 255, 255, 0.98);
      backdrop-filter: blur(8px);
      position: fixed;
      width: 100%;
      top: 0;
      z-index: 1000;
      border-bottom: 1px solid #e2e8f0;
      padding: 16px 0;
    }

    .nav {
      display: flex;
      justify-content: space-between;
      align-items: center;
    }

    .logo {
      font-size: 20px;
      font-weight: 700;
      color: #2b6cb0;
      text-decoration: none;
      letter-spacing: -0.5px;
    }

    .nav-links {
      display: flex;
      list-style: none;
      gap: 32px;
    }

    .nav-links a {
      text-decoration: none;
      color: #4a5568;
      font-weight: 500;
      font-size: 15px;
      transition: color 0.2s ease;
    }

    .nav-links a:hover {
      color: #2b6cb0;
    }

    /* Main sections */
    .section {
      padding: 40px 0;
    }

    .section:first-of-type {
      padding-top: 120px;
    }

    .section-divider {
      height: 1px;
      background: linear-gradient(90deg, transparent, #e2e8f0, transparent);
      margin: 10px 0;
    }

    /* Hero */
    .hero {
      text-align: center;
      padding: 80px 0 0;
    }

    .title-container {
      margin-bottom: 48px;
    }

    .hero-icon {
      width: 48px;
      height: 48px;
      margin: 0 auto 24px;
      display: block;
    }

    .hero-title {
      margin-bottom: 16px;
      font-weight: 700;
      letter-spacing: -1px;
    }

    .hero-subtitle {
      font-size: 1.25rem;
      color: #4a5568;
      font-weight: 400;
      max-width: 800px;
      margin: 0 auto;
    }

    /* Authors */
    .authors-section {
      margin: 48px 0;
    }

    .authors {
      font-size: 18px;
      line-height: 1.8;
      text-align: center;
      margin-bottom: 24px;
    }

    .author-block {
      display: inline;
      margin-right: 16px;
    }

    .author-block a {
      color: #2b6cb0;
      text-decoration: none;
      border-bottom: 1px solid transparent;
      transition: border-color 0.2s ease;
    }

    .author-block a:hover {
      border-bottom-color: #2b6cb0;
    }

    .affiliations {
      font-size: 16px;
      color: #718096;
      text-align: center;
      margin-bottom: 40px;
    }

    .publication-links {
      display: flex;
      justify-content: center;
      gap: 16px;
      flex-wrap: wrap;
    }

    .btn {
      display: inline-flex;
      align-items: center;
      padding: 12px 24px;
      background: #f7fafc;
      color: #2d3748;
      text-decoration: none;
      border: 1px solid #e2e8f0;
      border-radius: 6px;
      font-weight: 500;
      font-size: 15px;
      transition: all 0.2s ease;
    }

    .btn:hover {
      background: #edf2f7;
      border-color: #cbd5e0;
      transform: translateY(-1px);
    }

    .btn i {
      margin-right: 8px;
    }

    /* Video Section */
    .video-section {
      margin: 0px 0 30px 0;
    }

    .video-container {
      position: relative;
      max-width: 900px;
      margin: 0 auto;
      border-radius: 8px;
      overflow: hidden;
      box-shadow: 0 8px 32px rgba(0, 0, 0, 0.12);
      border: 1px solid #e2e8f0;
    }

    .video-container video {
      width: 100%;
      height: auto;
      display: block;
    }

    .video-controls {
      position: absolute;
      top: 16px;
      right: 16px;
      display: flex;
      gap: 8px;
    }

    .video-btn {
      background: rgba(0, 0, 0, 0.7);
      color: white;
      border: none;
      padding: 8px 12px;
      border-radius: 4px;
      cursor: pointer;
      font-size: 13px;
      transition: background 0.2s ease;
      backdrop-filter: blur(4px);
    }

    .video-btn:hover {
      background: rgba(0, 0, 0, 0.85);
    }

    .video-description {
      text-align: center;
      margin-top: 24px;
      font-size: 17px;
      color: #4a5568;
      max-width: 800px;
      margin-left: auto;
      margin-right: auto;
      line-height: 1.6;
    }

    /* Content sections */
    .section-title {
      font-size: 2rem;
      font-weight: 600;
      margin-bottom: 48px;
      text-align: center;
      letter-spacing: -0.5px;
    }

    .section-subtitle {
      font-size: 1.5rem;
      font-weight: 600;
      margin: 48px 0 24px;
      color: #2d3748;
      letter-spacing: -0.3px;
    }

    .content {
      max-width: 800px;
      margin: 0 auto;
      font-size: 17px;
      line-height: 1.7;
    }

    .content p {
      margin-bottom: 24px;
      color: #4a5568;
    }

    .content a {
      color: #2b6cb0;
      text-decoration: none;
      border-bottom: 1px solid transparent;
      transition: border-color 0.2s ease;
    }

    .content a:hover {
      border-bottom-color: #2b6cb0;
    }

    .highlight {
      background: #ebf8ff;
      color: #2b6cb0;
      padding: 2px 6px;
      border-radius: 3px;
      font-weight: 600;
    }

    /* Images */
    .section-image {
      display: block;
      max-width: 100%;
      height: auto;
      margin: 48px auto;
      border-radius: 8px;
      box-shadow: 0 4px 20px rgba(0, 0, 0, 0.08);
      border: 1px solid #e2e8f0;
    }

    .pipeline-image {
      max-width: 60%;
    }

    .interpolation-image {
      max-width: 50%;
    }

    /* Video Gallery */
    .video-gallery {
      display: grid;
      grid-template-columns: repeat(auto-fit, minmax(640px, 1fr));
      gap: 32px;
      margin: 48px 0;
    }

    .video-item {
      background: #ffffff;
      border: 1px solid #e2e8f0;
      border-radius: 8px;
      overflow: hidden;
      transition: all 0.2s ease;
    }

    .video-item:hover {
      box-shadow: 0 8px 25px rgba(0, 0, 0, 0.1);
      transform: translateY(-2px);
    }

    .video-item video {
      width: 100%;
      height: auto;
      object-fit: cover;
    }

    .video-item h4 {
      padding: 20px;
      font-size: 16px;
      color: #2d3748;
      text-align: center;
      font-weight: 500;
    }

    /* Open domain section */
    .open-domain-videos {
      display: flex;
      justify-content: center;
      gap: 40px;
      margin: 48px 0;
      flex-wrap: wrap;
    }

    .open-domain-item {
      text-align: center;
    }

    .open-domain-item video {
      width: 400px;
      max-width: 100%;
      border-radius: 8px;
      box-shadow: 0 4px 20px rgba(0, 0, 0, 0.08);
      border: 1px solid #e2e8f0;
    }

    .open-domain-item p {
      margin-top: 16px;
      font-size: 16px;
      color: #4a5568;
      font-weight: 500;
    }

    /* Citation */
    .citation-section {
      background: #f7fafc;
      border-top: 1px solid #e2e8f0;
      border-bottom: 1px solid #e2e8f0;
    }

    .citation-section h2 {
      color: #2d3748;
      margin-bottom: 32px;
    }

    .citation-code {
      background: #1a202c;
      color: #e2e8f0;
      padding: 24px;
      border-radius: 8px;
      overflow-x: auto;
      font-family: 'JetBrains Mono', monospace;
      font-size: 14px;
      line-height: 1.5;
      border: 1px solid #2d3748;
    }

    /* Footer */
    .footer {
      background: #f7fafc;
      padding: 48px 0;
      text-align: center;
      font-size: 15px;
      color: #718096;
      border-top: 1px solid #e2e8f0;
    }

    .footer a {
      color: #2b6cb0;
      text-decoration: none;
    }

    .footer a:hover {
      text-decoration: underline;
    }

    /* Scroll to top */
    .scroll-top {
      position: fixed;
      bottom: 24px;
      right: 24px;
      background: #2b6cb0;
      color: white;
      border: none;
      width: 48px;
      height: 48px;
      border-radius: 6px;
      cursor: pointer;
      display: none;
      align-items: center;
      justify-content: center;
      z-index: 1000;
      transition: all 0.2s ease;
      box-shadow: 0 4px 12px rgba(43, 108, 176, 0.3);
    }

    .scroll-top:hover {
      background: #2c5282;
      transform: translateY(-2px);
    }

    .scroll-top.visible {
      display: flex;
    }

    /* Responsive */
    @media (max-width: 768px) {
      .container {
        padding: 0 16px;
      }
      
      .hero-title {
        font-size: 2rem;
      }
      
      .nav-links {
        display: none;
      }
      
      .authors {
        font-size: 16px;
        line-height: 2;
      }
      
      .author-block {
        display: block;
        margin: 0 8px 8px 0;
      }
      
      .video-gallery {
        grid-template-columns: 1fr;
        gap: 24px;
      }
      
      .open-domain-videos {
        flex-direction: column;
        align-items: center;
        gap: 32px;
      }
      
      .open-domain-item video {
        width: 100%;
        max-width: 400px;
      }
      
      .section {
        padding: 60px 0;
      }
      
      .section:first-of-type {
        padding-top: 50px;
      }
    }

    @media (max-width: 480px) {
      h1 { font-size: 1.8rem; }
      h2 { font-size: 1.6rem; }
      h3 { font-size: 1.3rem; }
      
      .content {
        font-size: 16px;
      }
      
      .video-description {
        font-size: 16px;
      }
    }
  </style>
</head>

<body>
  <!-- Header -->
  <header class="header">
    <nav class="nav container">
      <a href="#" class="logo">KeyVID</a>
      <ul class="nav-links">
        <li><a href="#abstract">Abstract</a></li>
        <li><a href="#method">Method</a></li>
        <li><a href="#results">Results</a></li>
        <li><a href="#citation">Citation</a></li>
      </ul>
    </nav>
  </header>

  <!-- Hero Section -->
  <section class="section hero">
    <div class="container">
      <div class="title-container">
        <img src="./static/images/icon2.png" alt="KeyVID Icon" class="hero-icon">
        <h1 class="hero-title">KeyVID: Keyframe-Aware Video Diffusion for Audio-Synchronized Visual Animation</h1>
      </div>
      
      <div class="authors-section">
        <div class="authors">
          <span class="author-block">
            <a href="https://xingruiwang.github.io/">Xingrui Wang</a><sup>1,2</sup>,
          </span>
          <span class="author-block">
            <a href="https://joellliu.github.io/">Jiang Liu</a><sup>1</sup>,
          </span>
          <span class="author-block">
            <a href="https://zewang95.github.io/">Ze Wang</a><sup>1</sup>,
          </span>
          <span class="author-block">
            <a href="https://www.xiaodongyu.me/">Xiaodong Yu</a><sup>1</sup>,
          </span>
          <span class="author-block">
            <a href="https://jialianwu.com/">Jialian Wu</a><sup>1</sup>,
          </span>
          <span class="author-block">
            <a href="https://sunxm2357.github.io/">Ximeng Sun</a><sup>1</sup>,
          </span>
          <span class="author-block">
            <a href="https://yushengsu-thu.github.io/">Yusheng Su</a><sup>1</sup>
          </span>
        </div>
        <div class="authors">
          <span class="author-block">
            <a href="https://www.cs.jhu.edu/~ayuille/">Alan Yuille</a><sup>2</sup>
          </span>
          <span class="author-block">
            <a href="https://zicliu.wixsite.com/mysite">Zicheng Liu</a><sup>1</sup>
          </span>
          <span class="author-block">
            <a href="https://www.microsoft.com/en-us/research/people/">Emad Barsoum</a><sup>1</sup>
          </span>
        </div>

        <div class="affiliations">
          <span><sup>1</sup>Advanced Micro Devices, <sup>2</sup>Johns Hopkins University</span>
        </div>

        <div class="publication-links">
          <a href="https://arxiv.org/abs/2504.09656" class="btn">
            <i class="fas fa-file-alt"></i> arXiv
          </a>
          <a href="https://github.com/XingruiWang/KeyVID" class="btn">
            <i class="fab fa-github"></i> Code
          </a>
        </div>
      </div>
    </div>
  </section>

  <!-- Video Section -->
  <section class="video-section">
    <div class="container">
      <div class="video-container">
        <video id="teaser-video" autoplay preload muted loop playsinline>
          <source src="./static/videos/teaser.mp4" type="video/mp4">
          Your browser does not support the video tag.
        </video>
        <div class="video-controls">
          <button class="video-btn" onclick="toggleMute()">
            <span id="mute-text">ðŸ”‡ Sound Off</span>
          </button>
        </div>
      </div>
      <p class="video-description">
        KeyVID enables generation of intensive motion under high frame rate but only trained with low frame rate video data from conditioned audio.
      </p>
    </div>
  </section>

  <!-- Abstract Section -->
  <section class="section" id="abstract">
    <div class="container">
      <h2 class="section-title">Abstract</h2>
      <div class="content">
        <p>
          Generating video from various conditions, such as text, image, and audio, enables both spatial and temporal control, leading to high-quality generation results. 
          Videos with dramatic motions often require a higher frame rate to ensure smooth motion. Currently, most audio-to-visual animation models use uniformly sampled frames from video clips. 
          However, these uniformly sampled frames fail to capture significant key moments in dramatic motions at low frame rates and require significantly more memory when increasing the number of frames directly.
        </p>
        <p>
          In this paper, we propose <span class="highlight">KeyVID</span>, a keyframe-aware audio-to-visual animation framework that significantly improves the generation quality for key moments in audio signals while maintaining computation efficiency. 
          Given an image and an audio input, we first localize keyframe time steps from the audio. 
          Then, we use a keyframe generator to generate the corresponding visual keyframes. 
          Finally, we generate all intermediate frames using the motion interpolator. 
          Through extensive experiments, we demonstrate that KeyVID significantly improves audio-video synchronization and video quality across multiple datasets, particularly for highly dynamic motions.
        </p>
      </div>
    </div>
  </section>

  <div class="section-divider"></div>

  <!-- Method Section -->
  <section class="section" id="method">
    <div class="container">
      <h2 class="section-title">Audio-Synchronized Visual Animation</h2>
      <div class="content">
        <p>
          Audio-synchronized visual animation (ASVA) aims to animate objects from static images into videos with motion dynamics that are semantic and temporally aligned with input audio. 
          The audio conditions provide fine-grained control to the video generation, which requires the key action precisely aligned with the exact moment of audio signal.
        </p>
        <p>
          However, this synchronization is constrained by the frame rates of video generation models. The video diffusion model normally trains and generates videos at a fixed FPS. 
          Since audio carries fine-grained temporal information, the key moments in the audio can be lost in uniformly sampled low frame rate videos,
          leading to compromising audio-video synchronization.
        </p>
      </div>

      <h2 class="section-title" style="margin-top: 80px;">Keyframe-Aware Video Diffusion for ASVA</h2>
      <div class="content">
        <p>A straightforward solution is to train a video generation model on high frame rate data to match the fine-grained temporal information in audio. 
          However, this approach incurs substantial computational costs in terms of GPU memory and training time. 
          To ensure accurate audio-visual synchronization while maintaining computation efficiency, we propose KeyVID, a Keyframe-aware Video Diffusion framework that generates audio-synchronized video based on the input image and
          audio. Our model enables generating high frame rate videos but train on low frame rate by the three-step generation:
        </p>
      <img src="./static/images/Figure_pipeline.png" alt="Pipeline" class="section-image pipeline-image">
      </div>
      
      <div class="content">
        <h3 class="section-subtitle">I. Keyframe selection</h3>
        <p>
        We first develop a keyframe selection strategy that identifies critical moments in the video sequence based on an optical flow-based motion score. 
        We train a keyframe localizer that predicts such keyframe positions directly from the input audio cue.
        </p>
      
      <img src="./static/images/kf_selection.png" alt="keyframe selection" class="section-image">
      </div>
      
      <div class="content">
        <h3 class="section-subtitle">II. Keyframe generator</h3>
        <p>Next, instead of applying uniform downsampling to video frames, we select the keyframes to train a keyframe generator. 
        The keyframe generator explicitly captures crucial moments of dynamic motion that might otherwise be missed with uniform sampling without requiring an excessively high number of frames. 
        </p>
        <img src="./static/images/kf_gen.png" alt="keyframe generation" class="section-image">

      </div>
      <div class="content">
        <h3 class="section-subtitle">III. Keyframe interpolator</h3>
        <p>Then, we train a specialized motion interpolator to synthesize intermediate frames between the keyframes to generate high frame rate videos. 
        The motion interpolator ensures smooth motion transition and precise audio-visual synchronization throughout the sequence.
        </p>
        <img src="./static/images/figure-Interpolation.png" alt="Interpolating" class="section-image interpolation-image">
      </div>
    </div>
  </section>

  <div class="section-divider"></div>

  <!-- Results Section -->
  <section class="section" id="results">
    <div class="container">
      <h2 class="section-title">Generation Results</h2>
      <div class="content">
        <p>
          We generate these audio-synchronized videos on the <a href="https://lzhangbj.github.io/projects/asva/asva.html">AVSync15</a> dataset using KeyVID at 24 fps with 48 frames (2-second clips), where our keyframe-aware approach first selects 12 strategic keyframes based on audio-driven motion analysis, then interpolates to the full 48-frame sequence to achieve precise audio-visual synchronization for dynamic actions like "Dog barking," "Hammering," and "Playing cello."
        </p>
        <p>
        The video results (from left to right) show comparisons between: (a) our KeyVID with keyframe awareness, (b) our uniform sampling baseline (KeyVID-Uniform), (c) <a href="https://lzhangbj.github.io/projects/asva/asva.html">AVSyncD</a> state-of-the-art method, and (d) DynamiCrafter image-to-video baseline.
        </p>
      </div>

      <div class="video-gallery">
        <div class="video-item">
          <video muted loop controls playsinline>
            <source src="./static/videos/examples/yUZMpGwS-OI_000230_000240_2.5_6.5_clip-02.mp4" type="video/mp4">
          </video>
          <h4>"Machine gun shooting"</h4>
        </div>
        <div class="video-item">
          <video muted loop controls playsinline>
           <source src="./static/videos/examples/52ntwwQyv4_000070_000080_3.5_9.5_clip-02.mp4" type="video/mp4">
          </video>
          <h4>"Dog barking"</h4>
        </div>
        <div class="video-item">
          <video muted loop controls playsinline>
            <source src="./static/videos/examples/tzXSoaZ644_000021_000031_0.0_3.0_clip-01.mp4" type="video/mp4">
          </video>
          <h4>"Hammering"</h4>
        </div>
        <div class="video-item">
          <video muted loop controls playsinline>
            <source src="./static/videos/examples/0bC2T-xZkCs_000187_000197_0.0_3.0_clip-00.mp4" type="video/mp4">
          </video>
          <h4>"Playing trumpet"</h4>
        </div>
        <div class="video-item">
          <video muted loop controls playsinline>
            <source src="./static/videos/examples/1AfCMvhZJVY_000040_000050_0.5_3.5_clip-02.mp4" type="video/mp4">
          </video>
          <h4>"Toilet flushing"</h4>
        </div>
        <div class="video-item">
          <video muted loop controls playsinline>
            <source src="./static/videos/examples/2OLXoKxJ1qg_000030_000040_0.0_4.5_clip-01.mp4" type="video/mp4">
          </video>
          <h4>"Chicken crowing"</h4>
        </div>
        <div class="video-item">
          <video muted loop controls playsinline>
            <source src="./static/videos/examples/3qesirWAGt4_000020_000030_0.0_8.0_clip-00.mp4" type="video/mp4">
          </video>
          <h4>"Dog barking"</h4>
        </div>
        <div class="video-item">
          <video muted loop controls playsinline>
            <source src="./static/videos/examples/5Uodeo_Ln84_000014_000024_6.5_9.5_clip-01.mp4" type="video/mp4">
          </video>
          <h4>"Baby crying"</h4>
        </div>
        <div class="video-item">
          <video muted loop controls playsinline>
            <source src="./static/videos/examples/cap_gun.mp4" type="video/mp4">
          </video>
          <h4>"Cap gun shooting"</h4>
        </div>
        <div class="video-item">
          <video muted loop controls playsinline>
            <source src="./static/videos/examples/7HHCf9-HBiA_000000_000010_7.0_10.0_clip-01.mp4" type="video/mp4">
          </video>
          <h4>"Cap gun shooting"</h4>
        </div>
        <div class="video-item">
          <video muted loop controls playsinline>
            <source src="./static/videos/examples/74BDV0z_bvw_000030_000040_0.5_9.5_clip-00.mp4" type="video/mp4">
          </video>
          <h4>"Playing violin"</h4>
        </div>
        <div class="video-item">
          <video muted loop controls playsinline>
            <source src="./static/videos/examples/frog_cocking.mp4" type="video/mp4">
          </video>
          <h4>"Frog croaking"</h4>
        </div>
        <div class="video-item">
          <video muted loop controls playsinline>
            <source src="./static/videos/examples/Gwlez841U_I_000007_000017_0.0_3.0_clip-00.mp4" type="video/mp4">
          </video>
          <h4>"Lion roaring"</h4>
        </div>
        <div class="video-item">
          <video muted loop controls playsinline>
            <source src="./static/videos/examples/L_ucgLAe-TA_000599_000609_0.0_10.0_clip-00.mp4" type="video/mp4">
          </video>
          <h4>"Playing trombone"</h4>
        </div>
        <div class="video-item">
          <video muted loop controls playsinline>
            <source src="./static/videos/examples/lptpDgCE0N4_000083_000093_1.0_3.0_clip-02.mp4" type="video/mp4">
          </video>
          <h4>"Hammering"</h4>
        </div>
        <div class="video-item">
          <video muted loop controls playsinline>
            <source src="./static/videos/examples/sxJjC9HC1Xs_000310_000320_0.5_10.0_clip-01.mp4" type="video/mp4">
          </video>
          <h4>"Machine gun shooting"</h4>
        </div>
        <div class="video-item">
          <video muted loop controls playsinline>
            <source src="./static/videos/examples/yFuDYRwZ3EA_000237_000247_2.5_5.5_clip-02.mp4" type="video/mp4">
          </video>
          <h4>"Knife sharpening"</h4>
        </div>


      </div>
    </div>
 </section>

  <div class="section-divider"></div>

  <!-- Open Domain Generation Section -->
  <section class="section">
    <div class="container">
      <h2 class="section-title">Open Domain Generation</h2>
      <div class="content">
        <p>
          We generate open-domain videos by applying KeyVID to frames from Sora-generated content, controlling motion dynamics through different audio inputs. Using the same initial frame with hammering audio clips - one representing strikes on wooden surfaces and another on metal objects - our model adapts the generated motion based on material properties inferred from the audio, demonstrating KeyVID's capability to animate diverse scenarios beyond training data while maintaining semantic consistency between audio cues and visual dynamics.
        </p>
      </div>
      
      <div class="open-domain-videos">
        <div class="open-domain-item">
          <p>1. With audio of hitting wooden surface</p>
          <video controls preload playsinline>
            <source src="./static/videos/open_domain/hammering_wood.mp4" type="video/mp4">
          </video>
        </div>
        <div class="open-domain-item">
          <p>2. With audio of hitting metal surface</p>
          <video controls preload playsinline>
            <source src="./static/videos/open_domain/hammering_metal.mp4" type="video/mp4">
          </video>
        </div>
      </div>
    </div>
  </section>

  <div class="section-divider"></div>

  <!-- Citation Section -->
  <section class="section citation-section" id="citation">
    <div class="container">
      <h2 class="section-title">BibTeX</h2>
      <pre class="citation-code"><code>@article{wang2025keyvid,
  author    = {Wang, Xingrui and Liu, Jiang and Wang, Ze and Yu, Xiaodong and Wu, Jialian and Sun, Ximeng and Su, Yusheng and Yuille, Alan and Liu, Zicheng and Barsoum, Emad},
  title     = {KeyVID: Keyframe-Aware Video Diffusion for Audio-Synchronized Visual Animation},
  journal   = {arXiv preprint arXiv:2504.09656},
  year      = {2025},
}</code></pre>
    </div>
  </section>

  <!-- Footer -->
  <footer class="footer">
    <div class="container">
      <p>
        This website is licensed under a <a href="http://creativecommons.org/licenses/by-sa/4.0/">Creative Commons Attribution-ShareAlike 4.0 International License</a>.
      </p>
      <p>
        This means you are free to borrow the <a href="https://github.com/nerfies/nerfies.github.io">source code</a> of this website,
        we just ask that you link back to this page in the footer.
        Please remember to remove the analytics code included in the header of the website which
        you do not want on your website.
      </p>
    </div>
  </footer>

  <!-- Scroll to Top Button -->
  <button class="scroll-top" id="scrollTop">
    <i class="fas fa-arrow-up"></i>
  </button>

  <script>
    // Video controls
    function toggleMute() {
      const video = document.getElementById('teaser-video');
      const text = document.getElementById('mute-text');
      
      video.muted = !video.muted;
      text.textContent = video.muted ? 'ðŸ”‡ Sound Off' : 'ðŸ”Š Sound On';
    }

    // Smooth scrolling for navigation links
    document.querySelectorAll('a[href^="#"]').forEach(anchor => {
      anchor.addEventListener('click', function (e) {
        e.preventDefault();
        const target = document.querySelector(this.getAttribute('href'));
        if (target) {
          const headerHeight = document.querySelector('.header').offsetHeight;
          const targetPosition = target.offsetTop - headerHeight - 20;
          window.scrollTo({
            top: targetPosition,
            behavior: 'smooth'
          });
        }
      });
    });

    // Scroll to top button
    const scrollTopBtn = document.getElementById('scrollTop');
    
    window.addEventListener('scroll', function() {
      if (window.pageYOffset > 300) {
        scrollTopBtn.classList.add('visible');
      } else {
        scrollTopBtn.classList.remove('visible');
      }
    });

    scrollTopBtn.addEventListener('click', function() {
      window.scrollTo({
        top: 0,
        behavior: 'smooth'
      });
    });

    // Lazy loading for videos
    const videos = document.querySelectorAll('video');
    const videoObserver = new IntersectionObserver((entries) => {
      entries.forEach(entry => {
        if (entry.isIntersecting) {
          const video = entry.target;
          if (!video.src && video.querySelector('source')) {
            video.load();
          }
          videoObserver.unobserve(video);
        }
      });
    }, {
      rootMargin: '50px'
    });

    videos.forEach(video => {
      if (video.id !== 'teaser-video') { // Don't lazy load the main teaser video
        videoObserver.observe(video);
      }
    });

    // Handle video loading errors gracefully
    videos.forEach(video => {
      video.addEventListener('error', function() {
        const container = this.closest('.video-item') || this.closest('.open-domain-item');
        if (container) {
          container.style.opacity = '0.5';
          console.warn('Failed to load video:', this.querySelector('source')?.src);
        }
      });
    });
  </script>
</body>
</html>
